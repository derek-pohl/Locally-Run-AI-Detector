import os
import sys
import string
from openai import OpenAI

# --- Setup ---
# Use a library to load the .env file
try:
    from dotenv import load_dotenv
except ImportError:
    print("dotenv library not found. Please install it with 'pip install python-dotenv'")
    sys.exit(1)

# Use a library for cross-platform colored text
try:
    import colorama
except ImportError:
    print("colorama library not found. Please install it with 'pip install colorama'")
    sys.exit(1)

# --- Configuration and Initialization ---

# Initialize colorama
colorama.init(autoreset=True)
RED = colorama.Fore.RED
GREEN = colorama.Fore.GREEN
YELLOW = colorama.Fore.YELLOW
CYAN = colorama.Fore.CYAN

# Load environment variables from .env file
load_dotenv()

# Set up the OpenAI client
api_key = os.getenv("OPENAI_API_KEY")
if not api_key or api_key == "your_api_key_here":
    print(RED + "ERROR: OPENAI_API_KEY not found or not set in .env file.")
    print(YELLOW + "Please create a .env file and add your key: OPENAI_API_KEY='sk-...'")
    sys.exit(1)

client = OpenAI(api_key=api_key)
MODEL = "gpt-4o-mini" # Using the specified cost-effective and fast model

# --- Core Functions ---

def infer_prompt(text_to_analyze: str) -> str:
    """
    Phase 1: Send the text to the AI and ask it to guess the original prompt.
    """
    print(YELLOW + "Phase 1: Inferring the original prompt...")
    
    # Construct the prompt for the AI
    system_message = "You are an expert at reverse-engineering AI prompts."
    user_prompt = f"""Text:

{text_to_analyze}

End Text

The text above was likely generated by an AI. Based on the content and style, what was the most probable prompt given to the AI? Respond with only the prompt itself, without any extra commentary."""

    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.5 # A little creativity helps here
        )
        inferred_prompt = response.choices[0].message.content.strip()
        print(CYAN + f"Inferred Prompt: '{inferred_prompt}'\n")
        return inferred_prompt
    except Exception as e:
        print(RED + f"An error occurred during prompt inference: {e}")
        sys.exit(1)

def analyze_predictability(original_text: str, inferred_prompt: str):
    """
    Phase 2: Check the text word-by-word for predictability.
    """
    print(YELLOW + "Phase 2: Analyzing text predictability word by word...")
    print(YELLOW + "(This may take a moment. A '.' will be printed for each word checked.)")

    words = original_text.split()
    if len(words) <= 1:
        print(RED + "Text is too short to analyze.")
        return

    match_count = 0
    total_predictions = len(words) - 1
    colored_words = [words[0]] # Start with the first word, uncolored

    for i in range(1, len(words)):
        fragment = " ".join(words[:i])
        actual_next_word = words[i]

        try:
            # The core of the detector: see what the AI would naturally complete
            response = client.chat.completions.create(
                model=MODEL,
                messages=[
                    {"role": "user", "content": inferred_prompt},
                    {"role": "assistant", "content": fragment}
                ],
                temperature=0,  # Absolutely crucial for deterministic output
                max_tokens=5    # We only need the very next word
            )
            
            predicted_text = response.choices[0].message.content.strip()
            if not predicted_text:
                # Handle cases where the model returns nothing
                predicted_word = "" 
            else:
                predicted_word = predicted_text.split()[0]

            # Normalize for comparison: lowercase and remove punctuation
            # This handles cases like "dog." vs "dog"
            norm_actual = actual_next_word.strip(string.punctuation).lower()
            norm_predicted = predicted_word.strip(string.punctuation).lower()

            if norm_actual == norm_predicted:
                match_count += 1
                colored_words.append(RED + actual_next_word)
            else:
                colored_words.append(GREEN + actual_next_word)
            
            # Print progress indicator
            print(YELLOW + ".", end="", flush=True)

        except Exception as e:
            print(RED + f"\nAn error occurred during word prediction: {e}")
            # Color the rest of the text gray to show where the process stopped
            colored_words.append(colorama.Fore.LIGHTBLACK_EX + actual_next_word)
            for word in words[i+1:]:
                colored_words.append(colorama.Fore.LIGHTBLACK_EX + word)
            break
    
    print("\n\n" + "-"*40)
    print("Analysis Complete")
    print("-" * 40)

    # Print the final colored text
    print(" ".join(colored_words))
    print("-" * 40)

    # Print the score
    if total_predictions > 0:
        predictability_score = (match_count / total_predictions) * 100
        print(f"Result: {match_count} of {total_predictions} words were predicted correctly.")
        print(f"AI Predictability Score: {CYAN}{predictability_score:.2f}%")
        if predictability_score > 60:
            print(RED + "This text is highly predictable and likely AI-generated.")
        elif predictability_score > 35:
            print(YELLOW + "This text shows a mix of predictable and unpredictable patterns.")
        else:
            print(GREEN + "This text is highly unpredictable and likely human-written.")

# --- Main Execution Block ---
def main():
    """
    Main function to run the AI detector.
    """
    print(CYAN + "--- Command-Line AI Detector ---")
    print("Please paste the text you want to analyze below.")
    print("On a new line, press Ctrl+D (on Mac/Linux) or Ctrl+Z then Enter (on Windows) to finish.")
    print("-" * 35)

    # Read multi-line input from the user
    user_text = sys.stdin.read().strip()

    if not user_text:
        print(RED + "No text provided. Exiting.")
        return

    print("\n" + "-" * 35)
    inferred_prompt = infer_prompt(user_text)
    analyze_predictability(user_text, inferred_prompt)

if __name__ == "__main__":
    main()